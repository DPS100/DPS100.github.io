[
    {
        "title": "Portfolio Site",
        "date": "2024-01-15",
        "description": "A custom and easily configurable portfolio built with Javascript, HTML, and CSS. I can easily incorporate a new project simply by updating a few lines in the projects.json manifest!",
        "role":"Creator",
        "metadata": {
          "images": [

          ],
          "videos": [

          ],
          "media": [

          ],
          "links": [
            {"title": "Github", "link": "https://github.com/DPS100/DPS100.github.io"}
          ],
          "categories": [
            {"filter": "full-stack", "relevance": 0.5}
          ]
        }
    },
    {
        "title": "Whirly Tunes",
        "date": "2024-01-15",
        "description": "A robotic ensemble of colorful modules that produce a voicelike musical tone. I contributed to the research, prototyping, assembly, DAW communication, and creating a musical score to interface with the robot. This was my humanities final practicum in Musical Robotics, where we were tasked with creating musical robots and complimentary scores in order to explore pitch possibilities, types of form and development, and capabilities unique to machines.",
        "role":"Contributor",
        "metadata": {
          "images": [
            "assets/images/whirly-tunes.jpg"
          ],
          "videos": [
            "https://wp.wpi.edu/musicalmachines/files/2023/12/PXL_20231215_192046095.TS_.mp4"
          ],
          "media": [
            "assets/media/Whirly-tunes.pdf"
          ],
          "links": [
            {"title": "Read more", "link": "https://wp.wpi.edu/musicalmachines/2023/12/17/whirly-tunes/"},
            {"title": "Github", "link": "https://github.com/Kreeevin/WhirlyBoi"}
          ],
          "categories": [
            {"filter": "robotics", "relevance": 0.2}
          ]
        }
    },
    {
        "title": "Stop Motion Armature",
        "date": "2024-01-15",
        "description": "Short film project for my high school Film as Literature class, where I chose to make a stop motion movie. I designed, iterated, and 3D printed a custom armature from scratch, prototyping different kinds of actuating joints, hands, and facial expressions. I also created a short interface with OpenCV to quickly capture frames and play videos taken from these frames to preview the armature's movement.",
        "role":"Creator",
        "metadata": {
          "images": [

          ],
          "videos": [
            "https://www.youtube.com/embed/1XkwiTnlhTY"
          ],
          "media": [

          ],
          "links": [

          ],
          "categories": [
            {"filter": "robotics", "relevance": 0.1}
          ]
        }
    },
    {
        "title": "Data Synthesizer",
        "date": "2024-01-15",
        "description": "Final project for my graduate Machine Learning class. The goal was to train a supervised image classifier without any manually classified images by using another generative model to build the training dataset. The program will effectively dream by training itself on what it believes an image will look like. We created a robust and fault-tolerant synthetic data pipeline to sequentially generate images according to each class label. This was done in order to generate images in parallel across multiple machines without losing progress if one failed. Roughly 4,400 images were generated with stable diffusion over the span of a few days. We used PyTorch to train convolutional neural networks that perfomed with an accuracy of 90% on testing and validation sets they had never seen real data for. This could also be used to enhance existing datasets, where a model could be pre-trained on synthetic data to learn important features and later fine-tuned on real data.",
        "role":"Team lead",
        "metadata": {
          "images": [],
          "videos": [],
          "media": ["https://docs.google.com/presentation/d/e/2PACX-1vRED2ZWsUFcxnkx_TggazQzzxoHYn2Ir4EPJD5a2891_L3uKNd2oMGYfmbxnZTrtQ/embed?start=false&loop=true&delayms=3000"],
          "links": [
            {"title": "Github", "link": "https://github.com/DPS100/DataSynthesizer"}
          ],
          "categories": [
            {"filter": "data-science-ml", "relevance": 0.95}
          ]
        }
    },
    {
        "title": "Turing Machine Simulation",
        "date": "2024-01-15",
        "description": "Final project for my Foundations of Computer Science class. This project consisted of two parts: Creating a simulation of a turing machine, and designing a turing machine that could recognize if a string is a subsequence of another string. The turing machine simulator allows a user to provide a configuration file that defines the alphabet and state machine (essentially an instruction set for how the turing machine will run). See the readme file in the project github for a more detailed description of the program.",
        "role":"Creator",
        "metadata": {
          "images": [],
          "videos": [],
          "media": ["https://docs.google.com/presentation/d/e/2PACX-1vSlFCX9cupE4Ocpwg-h5iZdirlppeZMHfgUF3tQu0SgepLnA4FLGahaHRguWaOoqA/embed?start=false&loop=true&delayms=3000"],
          "links": [
            {"title": "Github", "link": "https://github.com/DPS100/3133-Turing-Final-Project"}
          ],
          "categories": [
            {"filter": "full-stack", "relevance": 0.1}
          ]
        }
    },
    {
        "title": "Robot Navigation",
        "date": "2024-01-15",
        "description": "The cumulative final project for my Unified Robotics IV: Navigation class to showcase our understanding of robot self localization and mapping (SLAM). The final demo consited of three parts: Mapping out an unknown maze, returning to the start position, and returning to the start position once again after being relocated to some random position in the maze at a random time. The robot itself is a turtlebot 3 burger running ROS, mapping it's immediate surroundings using a LIDAR sensor. It would report readings back to a host computer over ROS topics, which would estimate the position of the robot to the maze walls using a Kalman filter according to the internal wheel odometry and external wall positions. OpenCV was used to compute unexplored frontiers to investigate. An A* algorithm with a heuristic was used to determine the best frontier and how to navigate to it, and a cubic spline was provided for the turtlebot to follow. When the turtlebot detected it had been disturbed, it used Monte Carlo localization to find where it was in the maze, and return to the starting posiiton.",
        "role":"Contributor",
        "metadata": {
          "images": [],
          "videos": [],
          "media": ["assets/media/Lab4_RBE3002_Report (1).pdf"],
          "links": [
          ],
          "categories": [
            {"filter": "robotics", "relevance": 0.85}
          ]
        }
    },
    {
        "title": "Robot Pick and Place System",
        "date": "2024-01-15",
        "description": "The cumulative final project for my Unified Robotics III: Manipulation class. The demo entailed detecting objects of interest, determining their position in the workspace, and controlling the robotic arm to sort them into their respective bins. Both the controls for the OpenManipulator-X arm and vision processing pipeline were built using MATLAB. The arm consisted of four servos that could control position and velocity. Using the dimensions of the arm linkages and position of the servos, we could know the position of the arm in space with forward kinematics. Once the position of an object of interest was identified, we used inverse kinematics to determine the configuration of the arm to manipulate the target. In order to reach the target, we calculated the Jacobian of the end effector, which could be used to translate between the robot joint space and the working space. Using cubic trajectory interpolation and the Jacobain, we can generate a smooth control signal to manipulate the target objects.",
        "role":"Contributor",
        "metadata": {
          "images": [],
          "videos": ["https://www.youtube.com/embed/Q2C-VMDZcdc"],
          "media": ["assets/media/Lab5_Report_RBE3001.pdf"],
          "links": [],
          "categories": [
            {"filter": "robotics", "relevance": 0.95}
          ]
        }
    },
    {
        "title": "Jazzy Judy",
        "date": "2024-01-15",
        "description": "The robot built by my high school robotics team for the 2022 FIRST Robotics Competition game Rapid React. My interactions and responsibilities for other members of the team included distributing work to other programmers, teaching new members, communicating with other subteams what was in progress or needed to be done. I was also the operator during competitions, diagnosing problems and modifying the code on the fly according to the demands of the current match. The technical solutions I implemented for the robot ranged from game piece tracking using OpenCV and GRIP, automation of subsystems to keep the driver focused on important sections of the game, and creation of one of the best autonomous routines in the state. Here's some background on the competition to help put my contributions into context. The 2022 Rapid React First Robotics Competition consisted of two alliances of three robots from individual teams, each trying to score more points than the other. Points were scored by shooting game pieces, essentially basketball sized tennis balls, into a funnel at the center of the field. Additional bonus points could be scored by climbing monkey bars at the end of the match, or scoring balls autonomously in the first 15 seconds. Most of the programming I did was to make the driver's life easier: automatically moving towards balls, deploying the ball intake, moving the balls inside internally to the correct position, discarding the opposing team's balls, prepping the flywheels to take a shot, and calibrating the climbing sequence to move as quickly and safely up the rungs as possible. The task I am the most proud of is the four ball autonomous routine, where the robot collected and scored four game pieces in the first fifteen seconds of the game, which was a large factor in our success winning the Colorado regional and ranking 7th in our division of the international championship.",
        "role":"Lead Programmer",
        "metadata": {
          "images": [
            "assets/images/judy.jfif"
          ],
          "videos": [
            "https://www.youtube.com/embed/RvorwGZfUQQ",
            "https://www.youtube.com/embed/l-FUae_8Po4"
          ],
          "media": [

          ],
          "links": [
            {"title": "Angelbotics Website", "link": "https://angelbotics.org"},
            {"title": "Github", "link": "https://github.com/Angelbots1339/2022_Competition_Season"}
          ],
          "categories": [
            {"filter": "robotics", "relevance": 0.9},
            {"filter": "full-stack", "relevance": 0.3},
            {"filter": "data-science-ml", "relevance": 0.4}
          ]
        }
    }
]